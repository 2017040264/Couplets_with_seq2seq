{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddlenlp\n",
    "from functools import partial\n",
    "from paddle.static import InputSpec\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:08.517244Z",
     "iopub.status.busy": "2021-10-08T08:29:08.517011Z",
     "iopub.status.idle": "2021-10-08T08:29:08.520143Z",
     "shell.execute_reply": "2021-10-08T08:29:08.519561Z",
     "shell.execute_reply.started": "2021-10-08T08:29:08.517200Z"
    }
   },
   "outputs": [],
   "source": [
    "data_in_path=\"fixed_couplets_in.txt\"\n",
    "data_out_path=\"fixed_couplets_out.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:08.521169Z",
     "iopub.status.busy": "2021-10-08T08:29:08.520983Z",
     "iopub.status.idle": "2021-10-08T08:29:08.524426Z",
     "shell.execute_reply": "2021-10-08T08:29:08.523763Z",
     "shell.execute_reply.started": "2021-10-08T08:29:08.521133Z"
    }
   },
   "outputs": [],
   "source": [
    "def openfile(src):\n",
    "    with open(src,'r',encoding=\"utf-8\") as source:\n",
    "        lines=source.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:08.525849Z",
     "iopub.status.busy": "2021-10-08T08:29:08.525654Z",
     "iopub.status.idle": "2021-10-08T08:29:08.918499Z",
     "shell.execute_reply": "2021-10-08T08:29:08.917640Z",
     "shell.execute_reply.started": "2021-10-08T08:29:08.525812Z"
    }
   },
   "outputs": [],
   "source": [
    "data_in=openfile(data_in_path)\n",
    "data_out=openfile(data_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:08.920486Z",
     "iopub.status.busy": "2021-10-08T08:29:08.920145Z",
     "iopub.status.idle": "2021-10-08T08:29:08.983496Z",
     "shell.execute_reply": "2021-10-08T08:29:08.982816Z",
     "shell.execute_reply.started": "2021-10-08T08:29:08.920338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744915\n",
      "744915\n",
      "腾 飞 上 铁 ， 锐 意 改 革 谋 发 展 ， 勇 当 千 里 马 \n",
      "\n",
      "和 谐 南 供 ， 安 全 送 电 保 畅 通 ， 争 做 领 头 羊 \n",
      "\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(data_in))\n",
    "print(len(data_out))\n",
    "print(data_in[0])\n",
    "print(data_out[0])\n",
    "print(len(data_in[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:08.984631Z",
     "iopub.status.busy": "2021-10-08T08:29:08.984399Z",
     "iopub.status.idle": "2021-10-08T08:29:08.988544Z",
     "shell.execute_reply": "2021-10-08T08:29:08.987829Z",
     "shell.execute_reply.started": "2021-10-08T08:29:08.984589Z"
    }
   },
   "outputs": [],
   "source": [
    "def delete_newline_and_space(lista): \n",
    "    newlist=[]\n",
    "    for i in range(len(lista)):\n",
    "        newlist.append([\"<start>\"]+lista[i].strip().split()+['<end>'])\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:08.989510Z",
     "iopub.status.busy": "2021-10-08T08:29:08.989302Z",
     "iopub.status.idle": "2021-10-08T08:29:18.002326Z",
     "shell.execute_reply": "2021-10-08T08:29:18.001642Z",
     "shell.execute_reply.started": "2021-10-08T08:29:08.989471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', '腾', '飞', '上', '铁', '，', '锐', '意', '改', '革', '谋', '发', '展', '，', '勇', '当', '千', '里', '马', '<end>']\n",
      "['<start>', '和', '谐', '南', '供', '，', '安', '全', '送', '电', '保', '畅', '通', '，', '争', '做', '领', '头', '羊', '<end>']\n"
     ]
    }
   ],
   "source": [
    "data_in_nospace=delete_newline_and_space(data_in)\n",
    "data_out_nospace=delete_newline_and_space(data_out)\n",
    "\n",
    "print(data_in_nospace[0])\n",
    "print(data_out_nospace[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算最长的对联长度couplet_maxlen,并将该长度+2作为向量长。不足进行填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:18.003440Z",
     "iopub.status.busy": "2021-10-08T08:29:18.003216Z",
     "iopub.status.idle": "2021-10-08T08:29:18.184793Z",
     "shell.execute_reply": "2021-10-08T08:29:18.184134Z",
     "shell.execute_reply.started": "2021-10-08T08:29:18.003399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "couplet_maxlen=max([len(i) for i in data_in_nospace])\n",
    "couplet_maxlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看最长的对联：\n",
    "['旧', '画', '一', '张', '，', '龙', '不', '吟', '，', '虎', '不', '啸', '，', '花', '不', '闻', '香', '，', '鸟', '不', '叫', '，', '见', '此', '小', '子', '，', '好', '笑', '，', '好', '笑']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maxlen=0\n",
    "count=''\n",
    "for i in data_in_nospace:\n",
    "    if len(i)>maxlen:\n",
    "        maxlen=len(i)\n",
    "        count=i\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有个问题： 输入输出的语料库是二者分别建立一个，还是二者一起建立一个？\n",
    "\n",
    "在这里建立一个统一的语料库进行实验。（毕设的时候我是分开建的，不知道那个做法正确）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:18.185824Z",
     "iopub.status.busy": "2021-10-08T08:29:18.185625Z",
     "iopub.status.idle": "2021-10-08T08:29:18.189330Z",
     "shell.execute_reply": "2021-10-08T08:29:18.188758Z",
     "shell.execute_reply.started": "2021-10-08T08:29:18.185787Z"
    }
   },
   "outputs": [],
   "source": [
    "def bulid_cropus(data_in,data_out):\n",
    "    crpous=[]\n",
    "    for i in data_in:\n",
    "        crpous.extend(i)\n",
    "    for i in data_out:\n",
    "        crpous.extend(i)\n",
    "    return crpous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:18.190347Z",
     "iopub.status.busy": "2021-10-08T08:29:18.190159Z",
     "iopub.status.idle": "2021-10-08T08:29:18.195802Z",
     "shell.execute_reply": "2021-10-08T08:29:18.195117Z",
     "shell.execute_reply.started": "2021-10-08T08:29:18.190312Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_dict(corpus,frequency):\n",
    "    # 首先统计不同词（汉字）的频率，使用字典记录\n",
    "    word_freq_dict={}\n",
    "    for ch in corpus:\n",
    "        if ch not in word_freq_dict:\n",
    "            word_freq_dict[ch]=0\n",
    "        word_freq_dict[ch]+=1\n",
    "    \n",
    "    # 根据频率对字典进行排序\n",
    "    word_freq_dict=sorted(word_freq_dict.items(),key=lambda x:x[1],reverse=True)\n",
    "    \n",
    "    # 构造 词-id ,id-词 字典\n",
    "#     word2id_dict={'<pad>':0,\"<unk>\":1}\n",
    "#     id2word_dict={0:'<pad>',1:'<unk>'}\n",
    "    \n",
    "    word2id_dict={}\n",
    "    id2word_dict={}\n",
    "    \n",
    "    # 按照频率，从高到低，开始遍历每个单词，并赋予第一无二的 id\n",
    "    for word,freq in word_freq_dict:\n",
    "        if freq>frequency:\n",
    "            curr_id=len(word2id_dict)\n",
    "            word2id_dict[word]=curr_id\n",
    "            id2word_dict[curr_id]=word\n",
    "        else: \n",
    "            # else 部分在 使 单词 指向unk,对于汉字，我们不设置unk,令frequency=0\n",
    "            word2id_dict[word]=1\n",
    "    return word2id_dict,id2word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:18.196657Z",
     "iopub.status.busy": "2021-10-08T08:29:18.196475Z",
     "iopub.status.idle": "2021-10-08T08:29:22.349231Z",
     "shell.execute_reply": "2021-10-08T08:29:22.348352Z",
     "shell.execute_reply.started": "2021-10-08T08:29:18.196622Z"
    }
   },
   "outputs": [],
   "source": [
    "word_frequency=0\n",
    "word2id_dict,id2word_dict=build_dict(bulid_cropus(data_in_nospace,data_out_nospace),word_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词汇量大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:22.350438Z",
     "iopub.status.busy": "2021-10-08T08:29:22.350204Z",
     "iopub.status.idle": "2021-10-08T08:29:22.358266Z",
     "shell.execute_reply": "2021-10-08T08:29:22.357673Z",
     "shell.execute_reply.started": "2021-10-08T08:29:22.350396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "汉字个数： 9017 \n",
      " id个数： 9017\n"
     ]
    }
   ],
   "source": [
    "word_size=len(word2id_dict)\n",
    "id_size=len(id2word_dict)\n",
    "print(\"汉字个数：\",word_size,\"\\n id个数：\",id_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:22.359257Z",
     "iopub.status.busy": "2021-10-08T08:29:22.359034Z",
     "iopub.status.idle": "2021-10-08T08:29:22.374725Z",
     "shell.execute_reply": "2021-10-08T08:29:22.374111Z",
     "shell.execute_reply.started": "2021-10-08T08:29:22.359199Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"word2id.txt\",'w',encoding='utf-8') as w2i:\n",
    "    for i in list(id2word_dict.items()):\n",
    "        w2i.write(str(i)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:22.375615Z",
     "iopub.status.busy": "2021-10-08T08:29:22.375431Z",
     "iopub.status.idle": "2021-10-08T08:29:22.380222Z",
     "shell.execute_reply": "2021-10-08T08:29:22.379628Z",
     "shell.execute_reply.started": "2021-10-08T08:29:22.375579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(word2id_dict['<end>'])\n",
    "print(word2id_dict['<start>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:22.381071Z",
     "iopub.status.busy": "2021-10-08T08:29:22.380890Z",
     "iopub.status.idle": "2021-10-08T08:29:22.384722Z",
     "shell.execute_reply": "2021-10-08T08:29:22.384084Z",
     "shell.execute_reply.started": "2021-10-08T08:29:22.381037Z"
    }
   },
   "outputs": [],
   "source": [
    "def getensor(w2i,datalist,maxlength):\n",
    "    in_tensor=[]\n",
    "    for lista in datalist:\n",
    "        in_samll_tensor=[]\n",
    "        for li in lista:\n",
    "            in_samll_tensor.append(w2i[li])\n",
    "#         if len(in_samll_tensor)<maxlength:\n",
    "#             in_samll_tensor+=[w2i['<end>']]*(maxlength-len(in_samll_tensor))\n",
    "        in_tensor.append(in_samll_tensor)\n",
    "    return in_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:22.385559Z",
     "iopub.status.busy": "2021-10-08T08:29:22.385378Z",
     "iopub.status.idle": "2021-10-08T08:29:30.379183Z",
     "shell.execute_reply": "2021-10-08T08:29:30.378339Z",
     "shell.execute_reply.started": "2021-10-08T08:29:22.385525Z"
    }
   },
   "outputs": [],
   "source": [
    "in_tensor=getensor(word2id_dict,data_in_nospace,couplet_maxlen)\n",
    "out_tensor=getensor(word2id_dict,data_out_nospace,couplet_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:30.380456Z",
     "iopub.status.busy": "2021-10-08T08:29:30.380201Z",
     "iopub.status.idle": "2021-10-08T08:29:30.391453Z",
     "shell.execute_reply": "2021-10-08T08:29:30.390728Z",
     "shell.execute_reply.started": "2021-10-08T08:29:30.380414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744915 744915\n",
      "20 20\n",
      "9 9\n",
      "[0, 255, 68, 42, 554, 2, 2462, 63, 823, 923, 775, 252, 243, 2, 1098, 135, 13, 35, 102, 1] [0, 76, 339, 152, 1697, 2, 199, 461, 372, 1242, 861, 975, 273, 2, 334, 563, 723, 109, 421, 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(in_tensor),len(out_tensor))\n",
    "print(len(in_tensor[0]),len(out_tensor[0]))\n",
    "print(len(in_tensor[1]),len(out_tensor[1]))\n",
    "print(in_tensor[0],out_tensor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转成数字，带上shape属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:30.395501Z",
     "iopub.status.busy": "2021-10-08T08:29:30.395283Z",
     "iopub.status.idle": "2021-10-08T08:29:30.864498Z",
     "shell.execute_reply": "2021-10-08T08:29:30.863484Z",
     "shell.execute_reply.started": "2021-10-08T08:29:30.395463Z"
    }
   },
   "outputs": [],
   "source": [
    "in_tensor=np.array(in_tensor)\n",
    "out_tensor=np.array(out_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分训练集、验证集、测试集 ，按照8:1:1 固定划分\n",
    "595933-74491（670424）-74491（744915）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:30.867137Z",
     "iopub.status.busy": "2021-10-08T08:29:30.866906Z",
     "iopub.status.idle": "2021-10-08T08:29:30.871061Z",
     "shell.execute_reply": "2021-10-08T08:29:30.870435Z",
     "shell.execute_reply.started": "2021-10-08T08:29:30.867093Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_in_tensor=in_tensor[:595933]\n",
    "val_in_tensor=in_tensor[595933:670424]\n",
    "test_in_tensor=in_tensor[670424:]\n",
    "\n",
    "train_out_tensor=out_tensor[:595933]\n",
    "val_out_tensor=out_tensor[595933:670424]\n",
    "test_out_tensor=out_tensor[670424:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:30.872056Z",
     "iopub.status.busy": "2021-10-08T08:29:30.871854Z",
     "iopub.status.idle": "2021-10-08T08:29:30.877817Z",
     "shell.execute_reply": "2021-10-08T08:29:30.877243Z",
     "shell.execute_reply.started": "2021-10-08T08:29:30.872018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595933 74491 74491\n"
     ]
    }
   ],
   "source": [
    "print(len(train_in_tensor),len(test_in_tensor),len(val_in_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 封装数据集为可直接进行训练的dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:30.878678Z",
     "iopub.status.busy": "2021-10-08T08:29:30.878497Z",
     "iopub.status.idle": "2021-10-08T08:29:30.883221Z",
     "shell.execute_reply": "2021-10-08T08:29:30.882571Z",
     "shell.execute_reply.started": "2021-10-08T08:29:30.878643Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1.继承paddle.io.Dataset\n",
    "class Mydataset(paddle.io.Dataset):\n",
    "    \n",
    "    # 2. 构造函数，定义数据集大小\n",
    "    def __init__(self,first,second):\n",
    "        super(Mydataset,self).__init__()\n",
    "        self.first=first\n",
    "        self.second=second\n",
    "        \n",
    "    # 3. 实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）\n",
    "    def __getitem__(self,index):\n",
    "        return self.first[index],self.second[index]\n",
    "    \n",
    "    # 4. 实现__len__方法，返回数据集总数目\n",
    "    def __len__(self):\n",
    "        return self.first.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:30.884105Z",
     "iopub.status.busy": "2021-10-08T08:29:30.883905Z",
     "iopub.status.idle": "2021-10-08T08:29:30.887055Z",
     "shell.execute_reply": "2021-10-08T08:29:30.886508Z",
     "shell.execute_reply.started": "2021-10-08T08:29:30.884069Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tensor=Mydataset(train_in_tensor,train_out_tensor)\n",
    "val_tensor=Mydataset(val_in_tensor,val_out_tensor)\n",
    "test_tensor=Mydataset(test_in_tensor,test_out_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:30.887867Z",
     "iopub.status.busy": "2021-10-08T08:29:30.887689Z",
     "iopub.status.idle": "2021-10-08T08:29:30.892516Z",
     "shell.execute_reply": "2021-10-08T08:29:30.891919Z",
     "shell.execute_reply.started": "2021-10-08T08:29:30.887833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 255, 68, 42, 554, 2, 2462, 63, 823, 923, 775, 252, 243, 2, 1098, 135, 13, 35, 102, 1] [0, 76, 339, 152, 1697, 2, 199, 461, 372, 1242, 861, 975, 273, 2, 334, 563, 723, 109, 421, 1]\n"
     ]
    }
   ],
   "source": [
    "for a,b in train_tensor:\n",
    "    print(a,b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:30.893327Z",
     "iopub.status.busy": "2021-10-08T08:29:30.893133Z",
     "iopub.status.idle": "2021-10-08T08:29:30.895982Z",
     "shell.execute_reply": "2021-10-08T08:29:30.895358Z",
     "shell.execute_reply.started": "2021-10-08T08:29:30.893276Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "padid=word2id_dict['<end>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T15:04:51.719182Z",
     "iopub.status.busy": "2021-10-03T15:04:51.719004Z",
     "iopub.status.idle": "2021-10-03T15:04:51.725186Z",
     "shell.execute_reply": "2021-10-03T15:04:51.724558Z",
     "shell.execute_reply.started": "2021-10-03T15:04:51.719150Z"
    }
   },
   "source": [
    "def myPad(inputs,padid):\n",
    "   \n",
    "    arrs = [np.asarray(ele) for ele in inputs]\n",
    "    original_length = np.array([ele.shape[0] for ele in arrs])\n",
    "    max_size = max(original_length)\n",
    "    \n",
    "    result=[]\n",
    "    for i in range(len(arrs)):\n",
    "        if len(arrs[i])<max_size:\n",
    "            result.append(list(arrs[i])+[padid]*(max_length-len(arrs[i])))\n",
    "        else:\n",
    "            result.append(arrs[i])\n",
    "    \n",
    "    result=np.asarray(result)\n",
    "    print(type(result))\n",
    "    print(len(result))\n",
    "             \n",
    "    \n",
    "    return result,original_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T15:06:17.279337Z",
     "iopub.status.busy": "2021-10-03T15:06:17.278966Z",
     "iopub.status.idle": "2021-10-03T15:06:22.172596Z",
     "shell.execute_reply": "2021-10-03T15:06:22.171690Z",
     "shell.execute_reply.started": "2021-10-03T15:06:17.279283Z"
    }
   },
   "source": [
    "aa=[inputs[0] for inputs in train_tensor]\n",
    "\n",
    "src,src_length=myPad(aa,1)\n",
    "print(src_length.shape)\n",
    "print(src.shape)\n",
    "print(len(src[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T02:00:12.090716Z",
     "iopub.status.busy": "2021-10-04T02:00:12.090378Z",
     "iopub.status.idle": "2021-10-04T02:00:14.875766Z",
     "shell.execute_reply": "2021-10-04T02:00:14.875020Z",
     "shell.execute_reply.started": "2021-10-04T02:00:12.090666Z"
    }
   },
   "source": [
    "src,src_length=paddlenlp.data.Pad(pad_val=padid,ret_length=True)([inputsub[0] for inputsub in train_tensor])\n",
    "print(src.shape,src_length.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:30.896791Z",
     "iopub.status.busy": "2021-10-08T08:29:30.896612Z",
     "iopub.status.idle": "2021-10-08T08:29:30.901807Z",
     "shell.execute_reply": "2021-10-08T08:29:30.901139Z",
     "shell.execute_reply.started": "2021-10-08T08:29:30.896757Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_input(inputs,padid):\n",
    "\n",
    "    src,src_length=paddlenlp.data.Pad(pad_val=padid,ret_length=True)([inputsub[0] for inputsub in inputs])\n",
    "    trg,trg_length=paddlenlp.data.Pad(pad_val=padid,ret_length=True)([inputsub[1] for inputsub in inputs])\n",
    "    trg_mask =(trg[:,:-1]!=padid).astype(paddle.get_default_dtype())\n",
    "    return src,src_length,trg[:,:-1],trg[:,1:,np.newaxis],trg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:30.902620Z",
     "iopub.status.busy": "2021-10-08T08:29:30.902438Z",
     "iopub.status.idle": "2021-10-08T08:29:30.905904Z",
     "shell.execute_reply": "2021-10-08T08:29:30.905233Z",
     "shell.execute_reply.started": "2021-10-08T08:29:30.902586Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_data_loader(dataset):\n",
    "    data_loader=paddle.io.DataLoader(dataset,batch_sampler=None,batch_size=BATCH_SIZE,collate_fn=partial(prepare_input, padid=padid))\n",
    "    return data_loader\n",
    "# val_loader=paddle.io.DataLoader(val_tensor,batch_size=BATCH_SIZE,batch_sampler=None,collate_fn=partial(prepare_input, padid=padid))\n",
    "# test_loader=paddle.io.DataLoader(test_tensor,batch_size=BATCH_SIZE,batch_sampler=None,collate_fn=partial(prepare_input, padid=padid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:30.906785Z",
     "iopub.status.busy": "2021-10-08T08:29:30.906586Z",
     "iopub.status.idle": "2021-10-08T08:29:30.909909Z",
     "shell.execute_reply": "2021-10-08T08:29:30.909189Z",
     "shell.execute_reply.started": "2021-10-08T08:29:30.906749Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader=create_data_loader(train_tensor)\n",
    "val_loader=create_data_loader(val_tensor)\n",
    "test_loader=create_data_loader(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:30.910714Z",
     "iopub.status.busy": "2021-10-08T08:29:30.910535Z",
     "iopub.status.idle": "2021-10-08T08:29:36.803446Z",
     "shell.execute_reply": "2021-10-08T08:29:36.802732Z",
     "shell.execute_reply.started": "2021-10-08T08:29:30.910680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595933, 34)\n",
      "(595933,)\n",
      "(595933, 33)\n",
      "(595933, 33, 1)\n",
      "(595933, 33)\n"
     ]
    }
   ],
   "source": [
    "src=prepare_input(train_tensor,1)\n",
    "for i in src:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:36.804585Z",
     "iopub.status.busy": "2021-10-08T08:29:36.804374Z",
     "iopub.status.idle": "2021-10-08T08:29:39.220575Z",
     "shell.execute_reply": "2021-10-08T08:29:39.219896Z",
     "shell.execute_reply.started": "2021-10-08T08:29:36.804546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0 [64, 29]\n",
      "1 [64]\n",
      "2 [64, 28]\n",
      "3 [64, 28, 1]\n",
      "4 [64, 28]\n",
      "5\n",
      "0 [64, 28]\n",
      "1 [64]\n",
      "2 [64, 27]\n",
      "3 [64, 27, 1]\n",
      "4 [64, 27]\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "for i in train_loader:\n",
    "    print(len(i))\n",
    "    for ind,each in enumerate(i):\n",
    "        #print(ind,each.shape,each)\n",
    "        print(ind,each.shape)\n",
    "    j+=1\n",
    "    if j==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:39.221698Z",
     "iopub.status.busy": "2021-10-08T08:29:39.221481Z",
     "iopub.status.idle": "2021-10-08T08:29:39.236072Z",
     "shell.execute_reply": "2021-10-08T08:29:39.235431Z",
     "shell.execute_reply.started": "2021-10-08T08:29:39.221656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[64, 29], dtype=int32, place=CPUPlace, stop_gradient=True,\n",
      "       [[0   , 255 , 68  , ..., 1   , 1   , 1   ],\n",
      "        [0   , 3   , 542 , ..., 1   , 1   , 1   ],\n",
      "        [0   , 8   , 27  , ..., 1   , 1   , 1   ],\n",
      "        ...,\n",
      "        [0   , 190 , 3   , ..., 1   , 1   , 1   ],\n",
      "        [0   , 1128, 1751, ..., 1   , 1   , 1   ],\n",
      "        [0   , 102 , 32  , ..., 1   , 1   , 1   ]])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    x,x_length,y,_,_= i\n",
    "    break\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.网络搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:39.237011Z",
     "iopub.status.busy": "2021-10-08T08:29:39.236818Z",
     "iopub.status.idle": "2021-10-08T08:29:39.242217Z",
     "shell.execute_reply": "2021-10-08T08:29:39.241533Z",
     "shell.execute_reply.started": "2021-10-08T08:29:39.236974Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(paddle.nn.Layer):\n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_size,num_layers):\n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        self.embedding=paddle.nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.lstm=paddle.nn.LSTM(input_size=embedding_dim,\n",
    "                                hidden_size=hidden_size,\n",
    "                                num_layers=num_layers,\n",
    "                                dropout=0.2 if num_layers>1 else 0)\n",
    "            \n",
    "    # src_length 的形状为[batch_size],作用是控制inputs中的time_step超过[batch_size]的不再更新状态，就是那些填充\n",
    "    def forward(self,src,src_length):\n",
    "    #def forward(self,src):\n",
    "        inputs=self.embedding(src)  # [batch_size,time_steps,embedding_dim]\n",
    "        #encoder_out,encoder_state=self.lstm(inputs)\n",
    "        encoder_out,encoder_state=self.lstm(inputs,sequence_length=src_length) # out[batch_szie,time_steps,hidden_size] state:[[num_layers*1,batch_size,hidden_size],[num_layers*1,batch_size,hidden_size]]\n",
    "        # encoder_out,encoder_state=self.lstm(inputs)\n",
    "        return encoder_out,encoder_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T02:42:09.391347Z",
     "iopub.status.busy": "2021-10-04T02:42:09.390971Z",
     "iopub.status.idle": "2021-10-04T02:42:09.423204Z",
     "shell.execute_reply": "2021-10-04T02:42:09.422164Z",
     "shell.execute_reply.started": "2021-10-04T02:42:09.391298Z"
    }
   },
   "source": [
    "encoder=Encoder(word_size,256,128,2)\n",
    "#paddle.summary(encoder,[(64,18),(64)],dtypes='int64')\n",
    "out,state=encoder(x,x_length)\n",
    "print(out.shape)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:39.243131Z",
     "iopub.status.busy": "2021-10-08T08:29:39.242937Z",
     "iopub.status.idle": "2021-10-08T08:29:39.249680Z",
     "shell.execute_reply": "2021-10-08T08:29:39.249008Z",
     "shell.execute_reply.started": "2021-10-08T08:29:39.243094Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(paddle.nn.Layer):\n",
    "    def __init__(self,hidden_size):\n",
    "        super(AttentionLayer,self).__init__()\n",
    "        self.attn1=paddle.nn.Linear(hidden_size,hidden_size)\n",
    "        self.attn2=paddle.nn.Linear(hidden_size+hidden_size,hidden_size)\n",
    "\n",
    "    def forward(self,decoder_hidden_h,encoder_output,encoder_padding_mask):\n",
    "        \n",
    "        encoder_output=self.attn1(encoder_output) # [batch_size,time_steps,hidden_size]\n",
    "        \n",
    "        # decodr_hidden_h 的形状 [batch_size,hidden_size],是lstm公式中的ht.\n",
    "        # unsqueeze之后[batch_size,1,hidden_size]\n",
    "        # transpose_y=True,后两维转置 [batch_size,hidden_size,time_steps]\n",
    "        # matmul之后的 形状 [batch_size,1,time_steps]\n",
    "        a=paddle.unsqueeze(decoder_hidden_h,[1])\n",
    "        # print(a.shape)\n",
    "        # print(encoder_output.shape)\n",
    "        attn_scores=paddle.matmul(a,encoder_output,transpose_y=True)\n",
    "        \n",
    "        \n",
    "        # 注意力机制中增加掩码操作，在padding 位加上个非常小的数：-1e9\n",
    "        if encoder_padding_mask is not None:\n",
    "            # encoder_padding_mask的形状为[batch_size,1,time_steps]\n",
    "            attn_scores=paddle.add(attn_scores,encoder_padding_mask)\n",
    "\n",
    "        # softmax操作，默认是最后一个维度，axis=-1,形状不变\n",
    "        attn_scores=paddle.nn.functional.softmax(attn_scores) \n",
    "\n",
    "        # [batch_size,1,time_steps]*[batch_size,time_steps,hidden_size]-->[batch_size,1,hidden_size]\n",
    "        # squeeze之后：[batch_size,hidden_size]\n",
    "        attn_out=paddle.squeeze(paddle.matmul(attn_scores,encoder_output),[1])\n",
    "        \n",
    "        # concat之后 [batch_size,hidden_size+hidden_size]\n",
    "        attn_out=paddle.concat([attn_out,decoder_hidden_h],1)\n",
    "\n",
    "        # 最终结果[batch_size,hidden_size]\n",
    "        attn_out=self.attn2(attn_out)\n",
    "\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:39.250611Z",
     "iopub.status.busy": "2021-10-08T08:29:39.250416Z",
     "iopub.status.idle": "2021-10-08T08:29:39.257682Z",
     "shell.execute_reply": "2021-10-08T08:29:39.257094Z",
     "shell.execute_reply.started": "2021-10-08T08:29:39.250575Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderCell(paddle.nn.RNNCellBase):\n",
    "    def __init__(self,num_layers,embedding_dim,hidden_size):\n",
    "        super(DecoderCell,self).__init__()\n",
    "\n",
    "        self.dropout=paddle.nn.Dropout(0.2)\n",
    "        self.lstmcells=paddle.nn.LayerList([paddle.nn.LSTMCell(\n",
    "            input_size=embedding_dim+hidden_size if i==0 else hidden_size,\n",
    "            hidden_size=hidden_size\n",
    "        ) for i in range(num_layers)])\n",
    "\n",
    "        self.attention=AttentionLayer(hidden_size)\n",
    "    \n",
    "    def forward(self,decoder_input,decoder_initial_states,encoder_out,encoder_padding_mask=None):\n",
    "        #forward 函数会执行squence_len次 ，每次的decoder_input 为[batch_size,embeddding_dim]\n",
    "\n",
    "        # 状态分解 states [encoder_final_states,decoder_init_states]\n",
    "        # encoder_final_states [num_layes,batch_size,hiden_size] ???\n",
    "        # decoder_init_states [] ???\n",
    "\n",
    "        encoder_final_states,decoder_init_states=decoder_initial_states\n",
    "\n",
    "        #num_layers=len(encoder_final_states[0])\n",
    "        #decoder_init_states=lstm_init_state\n",
    "\n",
    "        # ???\n",
    "        new_lstm_states=[]\n",
    "\n",
    "        # decoder_input: [batch_size,embedding_dim]\n",
    "        # print(\"decodercell \",decoder_input.shape)\n",
    "        inputs=paddle.concat([decoder_input,decoder_init_states],1)\n",
    "        # print(\"concant之后\",inputs.shape)\n",
    "\n",
    "        for i ,lstm_cell in enumerate(self.lstmcells):\n",
    "\n",
    "            # inputs 的形状为 [batch_size,input_size]  input_size:输入的大小\n",
    "            state_h,new_lstm_state=lstm_cell(inputs,encoder_final_states[i])\n",
    "\n",
    "            inputs=self.dropout(state_h)\n",
    "\n",
    "            new_lstm_states.append(new_lstm_state)\n",
    "        \n",
    "        state_h=self.attention(inputs,encoder_out,encoder_padding_mask)\n",
    "\n",
    "        # print(state_h.shape)\n",
    "\n",
    "        return state_h,[new_lstm_states,state_h]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T02:59:45.488296Z",
     "iopub.status.busy": "2021-10-04T02:59:45.487933Z",
     "iopub.status.idle": "2021-10-04T02:59:45.499007Z",
     "shell.execute_reply": "2021-10-04T02:59:45.498297Z",
     "shell.execute_reply.started": "2021-10-04T02:59:45.488246Z"
    }
   },
   "source": [
    "in1 = np.array([[[1, 2, 3],\n",
    "                [4, 5, 6]],[[1, 2, 3],\n",
    "                [4, 5, 6]]])\n",
    "in2 = np.array([[[11, 12, 13],\n",
    "                [14, 15, 16]],[[11, 12, 13],\n",
    "                [14, 15, 16]]])\n",
    "in3 = np.array([[21, 22],\n",
    "                [23, 24]])\n",
    "in4 = np.array([[21, 22],\n",
    "[23, 24]])\n",
    "x1 = paddle.to_tensor(in1)\n",
    "x2 = paddle.to_tensor(in2)\n",
    "x3 = paddle.to_tensor(in3)\n",
    "x4 = paddle.to_tensor(in4)\n",
    "out1 = paddle.concat([x1, x2],1)\n",
    "out2 = paddle.concat([x3, x4],1)\n",
    "print(out1)\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:39.258611Z",
     "iopub.status.busy": "2021-10-08T08:29:39.258425Z",
     "iopub.status.idle": "2021-10-08T08:29:39.264146Z",
     "shell.execute_reply": "2021-10-08T08:29:39.263413Z",
     "shell.execute_reply.started": "2021-10-08T08:29:39.258575Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(paddle.nn.Layer):\n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_size,num_layers):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.embedding=paddle.nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.lstm_attention=paddle.nn.RNN(DecoderCell(num_layers,embedding_dim,hidden_size))\n",
    "        self.fianl=paddle.nn.Linear(hidden_size,vocab_size)\n",
    "\n",
    "    def forward(self,trg, decoder_initial_states,encoder_output,encoder_padding_mask):\n",
    "\n",
    "        # trg 的形状为 [batch_size,sequence_length]\n",
    "        # embedding 之后, [batch_size,sequence_length,embedding_dim]\n",
    "        inputs=self.embedding(trg)\n",
    "\n",
    "        # print(\"embedding 后的 输入维度\",inputs.shape)\n",
    "        \n",
    "        # decodr_out [batch_szie,hidden_size]\n",
    "        decoder_out,_ = self.lstm_attention(inputs,\n",
    "                                         initial_states=decoder_initial_states,\n",
    "                                         encoder_out=encoder_output,\n",
    "                                         encoder_padding_mask=encoder_padding_mask)\n",
    "\n",
    "        # predict [batch_size,sequence_len,word_size]\n",
    "        predict=self.fianl(decoder_out)\n",
    "        # print(\"最后的维度\",decoder_out.shape)\n",
    "\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:39.264997Z",
     "iopub.status.busy": "2021-10-08T08:29:39.264812Z",
     "iopub.status.idle": "2021-10-08T08:29:39.272239Z",
     "shell.execute_reply": "2021-10-08T08:29:39.271568Z",
     "shell.execute_reply.started": "2021-10-08T08:29:39.264962Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(paddle.nn.Layer):\n",
    "\n",
    "    def __init__(self, vocab_size,embedding_dim,hidden_size,num_layers,eos_id):\n",
    "        \n",
    "        super(Seq2Seq,self).__init__()\n",
    "\n",
    "        self.hidden_size=hidden_size\n",
    "        self.eos_id=eos_id\n",
    "        self.num_layers=num_layers\n",
    "        self.INF= 1e9\n",
    "\n",
    "        self.encoder=Encoder(vocab_size,embedding_dim,hidden_size,num_layers)\n",
    "        self.decoder=Decoder(vocab_size,embedding_dim,hidden_size,num_layers)\n",
    "        \n",
    "    def forward(self,src,src_length,trg):\n",
    "\n",
    "        # encoder_output 的形状为[batch_size,sequence_len,hidden_size]\n",
    "        # encoder_final_state ([num_layers*1,batch_size,hidden_size],[num_layers*1,batch_size,hidden_size]])  tuple类型\n",
    "        encoder_output,encoder_final_state=self.encoder(src,src_length)\n",
    "\n",
    "        encoder_final_states=[(encoder_final_state[0][i],encoder_final_state[1][i]) for i in range(self.num_layers)]\n",
    "        #print(encoder_final_states[0])\n",
    "\n",
    "        # [batch_size,hidden_size] 初始化为0\n",
    "        #lstm_init_state= self.decoder.lstm_attention.cell.get_initial_states(batch_ref=encoder_output,shape=[self.hidden_size])\n",
    "       \n",
    "        decoder_initial_states=[encoder_final_states,\n",
    "                                self.decoder.lstm_attention.cell.get_initial_states(batch_ref=encoder_output,shape=[self.hidden_size])]\n",
    "\n",
    "        src_mask=(src!=self.eos_id).astype(paddle.get_default_dtype())\n",
    "        encoder_mask=(src_mask-1)*self.INF\n",
    "        encoder_padding_mask=paddle.unsqueeze(encoder_mask,[1])\n",
    "\n",
    "        predict=self.decoder(trg,decoder_initial_states,encoder_output,encoder_padding_mask)\n",
    "\n",
    "        return predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:39.273060Z",
     "iopub.status.busy": "2021-10-08T08:29:39.272878Z",
     "iopub.status.idle": "2021-10-08T08:29:39.277772Z",
     "shell.execute_reply": "2021-10-08T08:29:39.277106Z",
     "shell.execute_reply.started": "2021-10-08T08:29:39.273025Z"
    }
   },
   "outputs": [],
   "source": [
    "class CrossEntropy(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropy,self).__init__()\n",
    "\n",
    "    def forward(self,pre,real,trg_mask):\n",
    "\n",
    "        # 返回的数据类型与pre一致，除了axis维度(未指定则为-1)，其他维度也与pre一致\n",
    "        # logits=pre,[batch_size,sequence_len,word_size],猜测会进行argmax操作，[batch_size,sequence_len,1]\n",
    "        # 默认的soft_label为False，lable=real,[bacth_size,sequence_len,1]\n",
    "        cost=paddle.nn.functional.softmax_with_cross_entropy(logits=pre,label=real)\n",
    "        \n",
    "        # 删除axis=2 shape上为1的维度\n",
    "        # 返回结果的形状应为 [batch_size,sequence_len]\n",
    "        cost=paddle.squeeze(cost,axis=[2])\n",
    "\n",
    "        # trg_mask 的形状[batch_size,suqence_len]\n",
    "        # * 这个星号应该是对应位置相乘，返回结果的形状 [bathc_szie,sequence_len]\n",
    "        masked_cost=cost*trg_mask\n",
    "\n",
    "        # paddle.mean 对应轴的对应位置求平均， 在这里返回结果为 [sequence_len]\n",
    "        # paddle.sum 求解方法与paddle.mean一致，最终返回的结果应为[1]\n",
    "        return paddle.sum(paddle.mean(masked_cost,axis=[0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:39.278583Z",
     "iopub.status.busy": "2021-10-08T08:29:39.278404Z",
     "iopub.status.idle": "2021-10-08T08:29:39.281851Z",
     "shell.execute_reply": "2021-10-08T08:29:39.281289Z",
     "shell.execute_reply.started": "2021-10-08T08:29:39.278548Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs=20\n",
    "\n",
    "eos_id=word2id_dict['<end>']\n",
    "num_layers=2\n",
    "dropout_rate=0.2\n",
    "hidden_size=128\n",
    "embedding_dim=256\n",
    "max_grad_norm=5\n",
    "lr=0.001\n",
    "log_freq=200\n",
    "model_path='./output/couplets_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:39.282658Z",
     "iopub.status.busy": "2021-10-08T08:29:39.282481Z",
     "iopub.status.idle": "2021-10-08T08:29:41.677307Z",
     "shell.execute_reply": "2021-10-08T08:29:41.676489Z",
     "shell.execute_reply.started": "2021-10-08T08:29:39.282624Z"
    }
   },
   "outputs": [],
   "source": [
    "s2s=Seq2Seq(word_size,embedding_dim,hidden_size,num_layers,eos_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:41.678475Z",
     "iopub.status.busy": "2021-10-08T08:29:41.678257Z",
     "iopub.status.idle": "2021-10-08T08:29:41.680922Z",
     "shell.execute_reply": "2021-10-08T08:29:41.680333Z",
     "shell.execute_reply.started": "2021-10-08T08:29:41.678435Z"
    }
   },
   "outputs": [],
   "source": [
    "# pre=s2s(x,x_length,y)\n",
    "# pre\n",
    "# paddle.summary(s2s,[(64,18),(64,17)],dtypes='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:41.681950Z",
     "iopub.status.busy": "2021-10-08T08:29:41.681755Z",
     "iopub.status.idle": "2021-10-08T08:29:41.686196Z",
     "shell.execute_reply": "2021-10-08T08:29:41.685557Z",
     "shell.execute_reply.started": "2021-10-08T08:29:41.681912Z"
    }
   },
   "outputs": [],
   "source": [
    "model=paddle.Model(s2s)\n",
    "\n",
    "# model.parameters() 返回一个包含所有模型参数的列表\n",
    "optimizer=paddle.optimizer.Adam(learning_rate=lr,parameters=model.parameters())\n",
    "\n",
    "# 困惑度\n",
    "ppl_metric=paddlenlp.metrics.Perplexity()\n",
    "\n",
    "model.prepare(optimizer,CrossEntropy(),ppl_metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:41.687048Z",
     "iopub.status.busy": "2021-10-08T08:29:41.686864Z",
     "iopub.status.idle": "2021-10-08T08:29:41.689871Z",
     "shell.execute_reply": "2021-10-08T08:29:41.689147Z",
     "shell.execute_reply.started": "2021-10-08T08:29:41.687013Z"
    }
   },
   "outputs": [],
   "source": [
    "# eval_freq 多少个epoch评估一次\n",
    "# save_freq 多少个epoch保存模型一次\n",
    "\n",
    "# model.fit(train_data=train_loader,\n",
    "#            eval_data=val_loader,\n",
    "#            epochs=epochs,\n",
    "#            eval_freq=1,\n",
    "#            save_freq=2,\n",
    "#            save_dir=model_path,\n",
    "#            log_freq=log_freq,\n",
    "#            verbose=2,\n",
    "#            callbacks=[paddle.callbacks.VisualDL('./log')])\n",
    "\n",
    "# # 保存用于预测的模型\n",
    "\n",
    "# model.save(\"./infer_model/infer_model\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:41.690785Z",
     "iopub.status.busy": "2021-10-08T08:29:41.690588Z",
     "iopub.status.idle": "2021-10-08T08:29:41.693393Z",
     "shell.execute_reply": "2021-10-08T08:29:41.692701Z",
     "shell.execute_reply.started": "2021-10-08T08:29:41.690748Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存网络模型，用于可视化\n",
    "\n",
    "# path = \"./train_model/train_model\"\n",
    "# paddle.jit.save(s2s, path,input_spec=[InputSpec(shape=[BATCH_SIZE,x.shape[1]],dtype='int64'),\n",
    "#                                           InputSpec(shape=[BATCH_SIZE], dtype='int64'),\n",
    "#                                           InputSpec(shape=[BATCH_SIZE,x.shape[1]], dtype='int64')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:41.694321Z",
     "iopub.status.busy": "2021-10-08T08:29:41.694114Z",
     "iopub.status.idle": "2021-10-08T08:29:41.703848Z",
     "shell.execute_reply": "2021-10-08T08:29:41.703135Z",
     "shell.execute_reply.started": "2021-10-08T08:29:41.694285Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqInfer(Seq2Seq):\n",
    "    def __init__(self,word_size,embedding_dim,hidden_size,num_layers,bos_id,eos_id,beam_size,max_out_len=couplet_maxlen):\n",
    "\n",
    "        self.bos_id=bos_id\n",
    "        self.beam_size=beam_size\n",
    "        self.max_out_len=max_out_len\n",
    "        self.num_layers=num_layers\n",
    "\n",
    "        super(Seq2SeqInfer,self).__init__(word_size,embedding_dim,hidden_size,num_layers,eos_id)\n",
    "\n",
    "        self.beam_search_decoder=paddle.nn.BeamSearchDecoder(\n",
    "            self.decoder.lstm_attention.cell,\n",
    "            start_token=bos_id,\n",
    "            end_token=eos_id,\n",
    "            beam_size=beam_size,\n",
    "            embedding_fn=self.decoder.embedding,\n",
    "            output_fn=self.decoder.fianl)\n",
    "    \n",
    "    def forward(self,src,src_length):\n",
    "        #encoder_output,encoder_states=self.encoder(src)\n",
    "        encoder_output,encoder_states=self.encoder(src,src_length)\n",
    "\n",
    "        encoder_final_state=[(encoder_states[0][i],encoder_states[1][i]) for i in range(self.num_layers)]\n",
    "\n",
    "        # 初始化decoder的隐藏层状态\n",
    "        decoder_initial_states=[encoder_final_state,\n",
    "                                self.decoder.lstm_attention.cell.get_initial_states(batch_ref=encoder_output,shape=[self.hidden_size])]\n",
    "        \n",
    "        src_mask=(src!=self.eos_id).astype(paddle.get_default_dtype())\n",
    "        encoder_padding_mask=(src_mask-1.0)*self.INF\n",
    "        encoder_padding_mask=paddle.unsqueeze(encoder_padding_mask,[1])\n",
    "\n",
    "        # 扩展tensor的bacth维度\n",
    "        encoder_out=paddle.nn.BeamSearchDecoder.tile_beam_merge_with_batch(encoder_output,self.beam_size)\n",
    "        \n",
    "        encoder_padding_mask=paddle.nn.BeamSearchDecoder.tile_beam_merge_with_batch(encoder_padding_mask,self.beam_size)\n",
    "\n",
    "        seq_output,_=paddle.nn.dynamic_decode( decoder=self.beam_search_decoder,\n",
    "                                               inits= decoder_initial_states,\n",
    "                                               max_step_num= self.max_out_len,\n",
    "                                               encoder_out=encoder_out,\n",
    "                                               encoder_padding_mask=encoder_padding_mask)\n",
    "        \n",
    "        return seq_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T06:17:02.568014Z",
     "iopub.status.busy": "2021-10-05T06:17:02.567833Z",
     "iopub.status.idle": "2021-10-05T06:17:02.571983Z",
     "shell.execute_reply": "2021-10-05T06:17:02.571306Z",
     "shell.execute_reply.started": "2021-10-05T06:17:02.567980Z"
    }
   },
   "source": [
    "def pre_process(seq,bos_idx,eos_idx,output_bos=False,output_eos=False):\n",
    "\n",
    "    # 结束位置\n",
    "    eos_pos=len(seq)-1\n",
    "\n",
    "    for i ,idx in enumerate(seq):\n",
    "        if idx==eos_idx: # 遇到结束标志\n",
    "            eos_pos=i\n",
    "            break\n",
    "\n",
    "    seq=[idx for idx in seq[:eos_pos+1] if (output_bos or idx !=bos_idx) and (output_eos or idx != eos_idx)]\n",
    "\n",
    "    return seq        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:41.704746Z",
     "iopub.status.busy": "2021-10-08T08:29:41.704553Z",
     "iopub.status.idle": "2021-10-08T08:29:41.708814Z",
     "shell.execute_reply": "2021-10-08T08:29:41.708165Z",
     "shell.execute_reply.started": "2021-10-08T08:29:41.704710Z"
    }
   },
   "source": [
    "def pre_process(seq,bos_idx,eos_idx):\n",
    "    #print(bos_idx,eos_idx)\n",
    "    # 结束位置\n",
    "    eos_pos=len(seq)-1\n",
    "\n",
    "    for i ,idx in enumerate(seq):\n",
    "        #print(i,idx[0])\n",
    "        if idx==eos_idx: # 遇到结束标志\n",
    "            eos_pos=i\n",
    "            break\n",
    "\n",
    "    seq=[idx[0] for idx in seq[:eos_pos] if (idx !=bos_idx) ]\n",
    "\n",
    "    return seq        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 预测超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:41.709797Z",
     "iopub.status.busy": "2021-10-08T08:29:41.709498Z",
     "iopub.status.idle": "2021-10-08T08:29:41.714166Z",
     "shell.execute_reply": "2021-10-08T08:29:41.713569Z",
     "shell.execute_reply.started": "2021-10-08T08:29:41.709656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "beam_size=10\n",
    "bos_id=word2id_dict['<start>']\n",
    "eos_id=word2id_dict['<end>']\n",
    "max_out_len=couplet_maxlen\n",
    "print(bos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:41.715035Z",
     "iopub.status.busy": "2021-10-08T08:29:41.714844Z",
     "iopub.status.idle": "2021-10-08T08:29:41.726939Z",
     "shell.execute_reply": "2021-10-08T08:29:41.726364Z",
     "shell.execute_reply.started": "2021-10-08T08:29:41.714999Z"
    }
   },
   "outputs": [],
   "source": [
    "infer_model=paddle.Model(Seq2SeqInfer(word_size,embedding_dim,hidden_size,num_layers,bos_id,eos_id,beam_size,max_out_len))\n",
    "\n",
    "infer_model.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 网络模型载入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T08:29:41.727766Z",
     "iopub.status.busy": "2021-10-08T08:29:41.727583Z",
     "iopub.status.idle": "2021-10-08T08:29:41.949028Z",
     "shell.execute_reply": "2021-10-08T08:29:41.948217Z",
     "shell.execute_reply.started": "2021-10-08T08:29:41.727731Z"
    }
   },
   "outputs": [],
   "source": [
    "infer_model.load('./output/couplets_models/18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T09:10:41.251358Z",
     "iopub.status.busy": "2021-10-08T09:10:41.251004Z",
     "iopub.status.idle": "2021-10-08T09:10:41.473965Z",
     "shell.execute_reply": "2021-10-08T09:10:41.473250Z",
     "shell.execute_reply.started": "2021-10-08T09:10:41.251306Z"
    }
   },
   "outputs": [],
   "source": [
    "#insrc='离离原上草'\n",
    "# 窗前明月光\n",
    "# 杀虫喷雾器  ;立马报春风\n",
    "# 色雅味佳，天堂美膳  ;风清气爽，世界佳肴\n",
    "\n",
    "def  Chinesetoid(insrc,word2id_dict,couplet_maxlen=couplet_maxlen,start=bos_id,padid=eos_id):\n",
    "\n",
    "    result=[start,]\n",
    "\n",
    "    for ch in insrc:\n",
    "        result.append(word2id_dict[ch])\n",
    "    \n",
    "    result.append(eos_id)\n",
    "    \n",
    "    result_len=len(result)\n",
    "\n",
    "    if len(result)<couplet_maxlen:\n",
    "        result+=[eos_id]*(couplet_maxlen-len(result))\n",
    "    \n",
    "    return paddle.unsqueeze(paddle.to_tensor(result),axis=0) ,paddle.to_tensor(result_len)\n",
    "\n",
    "# tensor=Chinesetoid(insrc,word2id_dict)\n",
    "# print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second(inputs,id2word_dict):\n",
    "\n",
    "    finished_seq=infer_model.predict_batch(inputs=list(inputs))[0][0]\n",
    "    #finished_seq=finished_seq[0][0]\n",
    "    #print(type(finished_seq))\n",
    " \n",
    "    input_re=inputs[0][0][1:]\n",
    "    input_re=paddle.tolist(input_re)\n",
    "    #print(input_re)\n",
    "\n",
    "    in_input=[]\n",
    "    for subre in input_re:\n",
    "        if subre==eos_id:\n",
    "            break\n",
    "        in_input.append(subre)\n",
    "    \n",
    "    #print(in_input)\n",
    "\n",
    "    \n",
    "    result=[]\n",
    "    for subseq in finished_seq:\n",
    "        #print(subseq)\n",
    "        resultid=Counter(list(subseq)).most_common(1)[0][0]\n",
    "        if resultid==eos_id:\n",
    "            break\n",
    "        result.append(resultid)\n",
    "    \n",
    "    #print(result)\n",
    "\n",
    "    \n",
    "    word_list_f=[id2word_dict[id] for id in in_input]\n",
    "    word_list_s=[id2word_dict[id] for id in result]\n",
    "\n",
    "    sequence='上联：'+\"\".join(word_list_f)+'\\t \\n下联: '+\"\".join(word_list_s)+\"\\n\"\n",
    "    #print(sequence)\n",
    "    return  sequence\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second=get_second(tensor,id2word_dict)\n",
    "print(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tkinter as tk  # 使用Tkinter前需要先导入\n",
    " \n",
    "# 第1步，实例化object，建立窗口window\n",
    "window = tk.Tk()\n",
    " \n",
    "# 第2步，给窗口的可视化起名字\n",
    "window.title('简易对联生成器')\n",
    " \n",
    "# 第3步，设定窗口的大小(长 * 宽)\n",
    "window.geometry('600x400')  # 这里的乘是小x\n",
    " \n",
    "# 第4步，在图形界面上设定输入框控件entry框并放置\n",
    "e = tk.Text(window,width=57,height=5,font=('楷体', 15), show = None)#显示成明文形式\n",
    "e.place(x=10,y=10)\n",
    "\n",
    "# ee = tk.Text(window,height=5, show = None)#显示成明文形式\n",
    "# ee.place(x=10,y=200)\n",
    "\n",
    "t = tk.Text(window,width=57, height=5,font=('楷体', 15))\n",
    "t.place(x=10,y=220)\n",
    " \n",
    "\n",
    "def insert_point(): \n",
    "    var = e.get('0.0','end')\n",
    "    var=var.strip()\n",
    "    #print('hhhh',var,type(var))\n",
    "    tensor=Chinesetoid(var,word2id_dict)\n",
    "    #ee.insert('end',str(tensor))\n",
    "    second=get_second(tensor,id2word_dict)\n",
    "    t.delete('1.0','end')\n",
    "    t.insert('end',second)\n",
    "    \n",
    "\n",
    "def delet():\n",
    "    e.delete('1.0','end')\n",
    " \n",
    "\n",
    "b1 = tk.Button(window, text='点我', width=10,\n",
    "               height=2, command=insert_point)\n",
    "b1.place(x=200,y=150)\n",
    "\n",
    "b2 = tk.Button(window, text='清空输入~', width=10,\n",
    "               height=2, command=delet)\n",
    "\n",
    "b2.place(x=300,y=150)\n",
    "\n",
    "l = tk.Label(window, text='输入最大长度为32，能识别的词汇大约在9000个，输入一些偏僻字可能会出错。---陈凡亮', font=('Arial', 10), height=2)\n",
    "\n",
    "l.pack(side='bottom')\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T09:28:00.265624Z",
     "iopub.status.busy": "2021-10-08T09:28:00.265054Z",
     "iopub.status.idle": "2021-10-08T09:28:04.721199Z",
     "shell.execute_reply": "2021-10-08T09:28:04.720404Z",
     "shell.execute_reply.started": "2021-10-08T09:28:00.265370Z"
    }
   },
   "source": [
    "idx=0\n",
    "for data in test_loader():\n",
    "    inputs=data[:2]\n",
    "    print(inputs[0],inputs[1])\n",
    "    \n",
    "    \n",
    "    finished_seq=infer_model.predict_batch(inputs=list(inputs))[0][0]\n",
    " \n",
    "    input_re=inputs[0][0][1:]\n",
    "    input_re=paddle.tolist(input_re)\n",
    "    in_input=[]\n",
    "    for subre in input_re:\n",
    "        if subre==eos_id:\n",
    "            break\n",
    "        in_input.append(subre)\n",
    "\n",
    "    \n",
    "    result=[]\n",
    "    for subseq in finished_seq:\n",
    "        resultid=Counter(subseq).most_common(1)[0][0]\n",
    "        if resultid==eos_id:\n",
    "            break\n",
    "        result.append(resultid)\n",
    "\n",
    "    \n",
    "\n",
    "    word_list_f=[id2word_dict[id] for id in in_input]\n",
    "    word_list_s=[id2word_dict[id] for id in result]\n",
    "\n",
    "    sequence='上联：'+\"\".join(word_list_f)+'\\t 下联:'+\"\".join(word_list_s)+\"\\n\"\n",
    "    print(sequence)\n",
    "\n",
    "    idx+=1\n",
    "\n",
    "    if idx==2:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idx=0\n",
    "for data in test_loader():\n",
    "    inputs=data[:2]\n",
    "\n",
    "    finished_seq=infer_model.predict_batch(inputs=list(inputs))[0]\n",
    "    finished_seq=finished_seq[:,:,np.newaxis] if len(finished_seq.shape)==2 else finished_seq\n",
    "    \n",
    "    finished_seq=np.transpose(finished_seq,[0,2,1])\n",
    "\n",
    "    for ins in finished_seq:\n",
    "        for beam in ins:\n",
    "            id_list=pre_process(beam,bos_id,eos_id)\n",
    "\n",
    "            word_list_f=[id2word_dict[id] for id in test_tensor[idx][0]] [1:-1]\n",
    "            word_list_s=[id2word_dict[id] for id in id_list]\n",
    "\n",
    "            sequence='上联：'+\"\".join(word_list_f)+'\\t 下联:'+\"\".join(word_list_s)+\"\\n\"\n",
    "            print(sequence)\n",
    "            idx+=1\n",
    "\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2rc1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
